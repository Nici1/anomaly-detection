{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From kmeans  ['./src', '/home/nikola/ML-E3/anomaly-detection-afterCleanUp/anomaly-detection/notebooks', '/home/nikola/anaconda3/envs/a_det2/lib/python38.zip', '/home/nikola/anaconda3/envs/a_det2/lib/python3.8', '/home/nikola/anaconda3/envs/a_det2/lib/python3.8/lib-dynload', '', '/home/nikola/anaconda3/envs/a_det2/lib/python3.8/site-packages', '../src']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-18 13:35:22.022452: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2024-04-18 13:35:22.022487: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import sklearn.metrics\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "import numpy as np\n",
    "from typing import Any, Dict, List, Tuple, Union\n",
    "from sklearn import metrics\n",
    "import sys\n",
    "sys.path.append('../src')\n",
    "\n",
    "from algorithms.kmeans import Kmeans\n",
    "from algorithms.dbscan import DBscan\n",
    "from algorithms.isolation_forest import IsolationForest\n",
    "from algorithms.percentile import Percentile\n",
    "\n",
    "from algorithms.gan import GAN\n",
    "from algorithms.border_check import BorderCheck\n",
    "from algorithms.svm import SVM\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin, TransformerMixin\n",
    "from sklearn.utils.validation import check_X_y, check_array, check_is_fitted\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "from sklearn.metrics import euclidean_distances\n",
    "from sklearn.model_selection import GridSearchCV, TimeSeriesSplit\n",
    "from sklearn.utils.estimator_checks import check_estimator\n",
    "import csv\n",
    "import os\n",
    "import multiprocessing as mp\n",
    "import time\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes = []\n",
    "dataframes_train = []\n",
    "dataframes_validation = []\n",
    "dataframes_test = []\n",
    "\n",
    "# Create nine pandas DataFrame objects in a loop\n",
    "for i in range(1, 10, 1):\n",
    "    df = pd.read_csv(f\"../data/ads-{i}.csv\")\n",
    "    dataframes.append(df)\n",
    "\n",
    "    \n",
    "    dy_dx = np.gradient(df['ftr_vector'], df['timestamp'])\n",
    "    ftr_vector_strings = []\n",
    "    for i in range(len(df)):\n",
    "        ftr_vector_strings.append(str([df['ftr_vector'].iloc[i], dy_dx[i]]))\n",
    "\n",
    "    # Assign the list of strings back to the 'ftr_vector' column\n",
    "    df['ftr_vector'] = ftr_vector_strings\n",
    "\n",
    "    total_size = len(df)\n",
    "    train_size = int(total_size * 0.6)\n",
    "    val_size = int(total_size * 0.2)\n",
    "\n",
    "    # Split the DataFrame\n",
    "    train_df = df[:train_size]\n",
    "    dataframes_train.append(train_df)\n",
    "\n",
    "    val_df = df[train_size:train_size+val_size].reset_index(drop=True)\n",
    "    dataframes_validation.append(val_df)\n",
    "\n",
    "\n",
    "    test_df = df[train_size+val_size:].reset_index(drop=True)\n",
    "    dataframes_test.append(test_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(dataframes_train[0]))\n",
    "print(len(dataframes_validation[0]))\n",
    "print(len(dataframes_test[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes_test[1].iloc[0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/train2/ads-1.csv')\n",
    "df.iloc[0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "for j in range(1, 10, 1):\n",
    "    df = dataframes[j]\n",
    "    dy_dx = np.gradient(df['ftr_vector'], df['timestamp'])\n",
    "    ftr_vector_strings = []\n",
    "    for i in range(len(df)):\n",
    "        ftr_vector_strings.append([str(df['ftr_vector'].iloc[i]), str(dy_dx[i])])\n",
    "\n",
    "    # Assign the list of strings back to the 'ftr_vector' column\n",
    "    df['ftr_vector'] = ftr_vector_strings\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(y_true, y_predicted):\n",
    "    confusion_matrix = sklearn.metrics.confusion_matrix(y_true, y_predicted)\n",
    "    precision = sklearn.metrics.precision_score(y_true, y_predicted)\n",
    "    recall = sklearn.metrics.recall_score(y_true, y_predicted)\n",
    "    f1 = sklearn.metrics.f1_score(y_true, y_predicted)\n",
    "    accuracy = sklearn.metrics.accuracy_score(y_true, y_predicted)\n",
    "\n",
    "    return {\"confusion matrix \": confusion_matrix, \"precision \": precision, \"recall \": recall, \"f1 \": f1, \"accuracy \" : accuracy}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "param_grid_Kmeans = {\n",
    "    \"n_clusters\": np.arange(2, 4),\n",
    "    \"treshold\": np.arange(0.1, 1, 0.1),\n",
    "}\n",
    "\n",
    "param_grid_DBscan = {\n",
    "    \"eps\": np.arange(0.5, 1.5, 0.5),\n",
    "    \"treshold\": np.arange(0.5, 2, 0.5),\n",
    "    \"min_samples\": np.arange(1, 3, 1),\n",
    "}\n",
    "\n",
    "algorithms_params = [param_grid_Kmeans] \n",
    "algorithms = [\"Kmeans\"]\n",
    "\n",
    "metrics = np.empty([2, 2, 5], dtype=object)\n",
    "\n",
    "for i in range(1,2):\n",
    "\n",
    "    df_test = pd.read_csv(f\"data/sensor-cleaning-data/cleaned/test/reformatted/data1.csv\")\n",
    "\n",
    "    y_true = df_test[[\"error\"]]\n",
    "\n",
    "    for alg_id, alg in enumerate(algorithms_params):\n",
    "        score = []\n",
    "        for params in itertools.product(*alg.values()):\n",
    "\n",
    "            inner_dict = {k: v for (k, v) in zip(algorithms_params[alg_id].keys(), params)}\n",
    "\n",
    "            conf = {\n",
    "                \"filtering\": \"None\",\n",
    "                \"train_data\": f\"data/sensor-cleaning-data/cleaned/train/data{i}.csv\",\n",
    "                \"input_vector_size\": 1,\n",
    "                \"warning_stages\": [0.7, 0.9],\n",
    "                **inner_dict,\n",
    "                \"output\": [],\n",
    "                \"output_conf\": [{}\n",
    "                ],\n",
    "            }\n",
    "\n",
    "            class_name = algorithms[alg_id]\n",
    "\n",
    "            class_ = globals()[class_name]\n",
    "\n",
    "            detector = class_(conf)\n",
    "\n",
    "            mask = []\n",
    "            y_predicted = []\n",
    "\n",
    "            for idx, row in df_test.iterrows():\n",
    "\n",
    "                status_code = detector.message_insert(\n",
    "                    {\n",
    "                        \"timestamp\": df_test[\"offset\"].iloc[idx],\n",
    "                        \"ftr_vector\": [df_test[\"val\"].iloc[idx]],\n",
    "                    }\n",
    "                )\n",
    "\n",
    "                if status_code == 2:\n",
    "                    y_predicted.append(False)\n",
    "                if status_code == 1:\n",
    "                    y_predicted.append(False)\n",
    "                elif status_code == -1:\n",
    "                    y_predicted.append(True)\n",
    "\n",
    "\n",
    "            m = compute_metrics(y_predicted, y_true)\n",
    "            m.append(params)\n",
    "            score.append(m)\n",
    "            print(m)\n",
    "            #print(f\"{algorithms[alg_id]}\", score)\n",
    "        #print(max(score, key=lambda x: x[0]))\n",
    "        # max_list = max(score, key=lambda x: x[3])\n",
    "\n",
    "        # metrics[alg_id, i-1, :] = max_list\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "df_test = pd.read_csv(f\"data/sensor-cleaning-data/cleaned/test/reformatted/data1.csv\")\n",
    "# select to columns from dataframe\n",
    "X = df_test[[\"offset\", \"val\"]]\n",
    "y = df_test[[\"error\"]]\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Estimator(BaseEstimator):\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        \n",
    "        train_data=\"data/train/ads-1.csv\",\n",
    "        alg = \"Kmeans\",\n",
    "\n",
    "        # Kmeans \n",
    "        n_clusters=1,\n",
    "        treshold=1,\n",
    "\n",
    "        #DBscan\n",
    "        eps = 0.5,\n",
    "        db_treshold=1,\n",
    "        min_samples = 2,\n",
    "\n",
    "        #IsolationForest\n",
    "        max_samples = 100,\n",
    "        max_features=1,\n",
    "        contamination = 0.05,\n",
    "\n",
    "        # GAN\n",
    "        N_latent=3,\n",
    "        K=8,\n",
    "        len_window=500,\n",
    "\n",
    "        # BorderCheck\n",
    "        UL=0.5,\n",
    "        LL=-0.5,\n",
    "\n",
    "        #Percentile\n",
    "        percentile_range = [(1, 99)],\n",
    "        buff_size = [50]\n",
    "        \n",
    "       \n",
    "    ):\n",
    "        self.train_data = train_data\n",
    "        self.alg = alg\n",
    "\n",
    "        # Kmeans\n",
    "        self.n_clusters = n_clusters\n",
    "        self.treshold = treshold\n",
    "\n",
    "        # DBscan\n",
    "        self.eps = eps\n",
    "        self.min_samples = min_samples\n",
    "        self.db_treshold = db_treshold\n",
    "\n",
    "        # IsolationForest\n",
    "        self.max_samples = max_samples \n",
    "        self.max_features = max_features\n",
    "        self.contamination = contamination\n",
    "\n",
    "        # GAN\n",
    "        self.N_latent = N_latent\n",
    "        self.K = K\n",
    "        self.len_window = len_window\n",
    "\n",
    "        # BorderCheck\n",
    "        self.UL = UL\n",
    "        self.LL = LL \n",
    "\n",
    "        # Percentile\n",
    "        self.percentile_range = percentile_range\n",
    "        self.buff_size = buff_size\n",
    "\n",
    "\n",
    "    def fit(self, X, y):\n",
    "\n",
    "        inner_dict = {\n",
    "            \"train_data\": self.train_data,\n",
    "            # Kmeans\n",
    "            \"n_clusters\": self.n_clusters,\n",
    "            \"treshold\": self.treshold,\n",
    "            # DBscan\n",
    "            \"eps\": self.eps,\n",
    "            \"min_samples\": self.min_samples,\n",
    "            \"db_treshold\": self.db_treshold,\n",
    "            # IsolationForest\n",
    "            \"max_samples\": self.max_samples,\n",
    "            \"max_features\": self.max_features,\n",
    "            \"contamination\": self.contamination,\n",
    "            # GAN\n",
    "            \"N_latent\": self.N_latent,\n",
    "            \"K\": self.K,\n",
    "            \"len_window\": self.len_window,\n",
    "            # BorderCheck\n",
    "            \"UL\": self.UL,\n",
    "            \"LL\": self.LL,\n",
    "            # Percentile\n",
    "            \"percentile_range\": self.percentile_range,\n",
    "            \"buff_size\": self.buff_size\n",
    "\n",
    "        }\n",
    "\n",
    "        conf = {\n",
    "            \"filtering\": \"None\",\n",
    "            \"input_vector_size\": 2,\n",
    "            \"warning_stages\": [0.7, 0.9],\n",
    "            \"model_name\":\"IsolationForest\",\n",
    "            **inner_dict,\n",
    "            \"output\": [],\n",
    "            \"output_conf\": [{}],\n",
    "        }\n",
    "\n",
    "      \n",
    "\n",
    "        class_ = globals()[self.alg]\n",
    "        self.detector_ = class_(conf)\n",
    "\n",
    "        self.is_fitted_ = True\n",
    "\n",
    "        # `fit` should always return `self`\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        \n",
    "        y_predicted = []\n",
    "                \n",
    "    \n",
    "        # transverse X rows\n",
    "        \n",
    "        for idx, row in X.iterrows():\n",
    "            \n",
    "          \n",
    "            message = {\n",
    "                \"timestamp\": row[\"timestamp\"],\n",
    "                \"ftr_vector\": [row[\"ftr_vector\"]],\n",
    "            }\n",
    "          \n",
    "        \n",
    "            status_code = self.detector_.message_insert(message)\n",
    "\n",
    "            if status_code == 2 or status_code ==0:\n",
    "                y_predicted.append(False)\n",
    "            if status_code == 1:\n",
    "                y_predicted.append(False)\n",
    "            elif status_code == -1:\n",
    "                y_predicted.append(True)\n",
    "\n",
    "           \n",
    "       \n",
    "      \n",
    "\n",
    "        \n",
    "        return y_predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "algorithms = [\"DBscan\", \"IsolationForest\"]\n",
    "\n",
    "DBscan_params = {\n",
    "    \n",
    "    \"alg\": [\"DBscan\"],\n",
    "   \n",
    "    # DBscan\n",
    "    \"eps\": np.arange(0.2, 1, 0.2),\n",
    "    \"db_treshold\": np.arange(0.2, 1, 0.2),\n",
    "    \"min_samples\": [100],\n",
    "   \n",
    "}\n",
    "\n",
    "Kmeans_params = {\n",
    "    \n",
    "    \"alg\": [\"Kmeans\"],\n",
    "    # Kmeans\n",
    "    \"n_clusters\": [ 2, 4, 6],\n",
    "    \"treshold\": np.arange(0.05, 1.05, 0.15),\n",
    "}\n",
    "\n",
    "IsolationForest_params = {\n",
    "    \"alg\": [\"IsolationForest\"],\n",
    "  \n",
    "    # IsolationForest\n",
    "    \"max_samples\": [2500],\n",
    "    \"max_features\": [1],\n",
    "    \"contamination\": [0.0005, 0.001, 0.003, 0.008],\n",
    "\n",
    "}\n",
    "\n",
    "BorderCheck_params = {\n",
    "    \"alg\": [\"BorderCheck\"],\n",
    "  \n",
    "    \"UL\": np.arange(0.3, 2.1, 0.2),\n",
    "    \"LL\": np.arange(-0.1, -2.1, -0.2),\n",
    "\n",
    "}\n",
    "\n",
    "first_values = [0.2, 0.5, 0.7, 1, 2]\n",
    "second_values = [99, 99.2, 99.5, 99.8, 99.95]  \n",
    "\n",
    "# Create a list of tuples with all combinations of values\n",
    "list_of_tuples = [(first, second) for first, second in itertools.product(first_values, second_values)]\n",
    "\n",
    "Percentile_params = {\n",
    "    \"alg\": [\"Percentile\"],\n",
    "  \n",
    "    \"percentile_range\":list_of_tuples,\n",
    "    \"buff_size\": [1000]\n",
    "\n",
    "}\n",
    "\n",
    "\n",
    "SVM_params = {\n",
    "   \n",
    "\n",
    "}\n",
    "\n",
    "\n",
    "for alg in algorithms:\n",
    "\n",
    "    for i in range(1, 10, 1):\n",
    "\n",
    "        df_validation = dataframes_validation[i]\n",
    "        X_validation = df_validation[[\"timestamp\", \"ftr_vector\"]]\n",
    "        y_validation = df_validation[[\"label\"]]\n",
    "\n",
    "\n",
    "        df_test = dataframes_test[i]\n",
    "        X_test = df_test[[\"timestamp\", \"ftr_vector\"]]\n",
    "        y_test = df_test[[\"label\"]]\n",
    "\n",
    "\n",
    "        test_params = {\n",
    "            \n",
    "            # Kmeans\n",
    "            \"n_clusters\": [2],\n",
    "            \"treshold\": [0.5],\n",
    "\n",
    "            # DBscan\n",
    "            \"eps\": [0.5],\n",
    "            \"db_treshold\": [0.5],\n",
    "            \"min_samples\": [100],\n",
    "\n",
    "            # IsolationForest\n",
    "            \"max_samples\": [10],\n",
    "            \"max_features\": [1],\n",
    "            \"contamination\": [0.01],\n",
    "\n",
    "            # GAN\n",
    "            \"N_latent\": [3],\n",
    "            \"K\": [8],\n",
    "            \"len_window\": [500],\n",
    "\n",
    "            # Border Check\n",
    "            \"UL\": [0.5],\n",
    "            \"LL\":  [-0.5],\n",
    "\n",
    "            # Percentile\n",
    "            \"percentile_range\":[(1,99)],\n",
    "            \"buff_size\":[100],\n",
    "\n",
    "            **eval(f\"{alg}_params\"),\n",
    "            \"train_data\": [f\"../data/train2/ads-{i}.csv\"],\n",
    "     \n",
    "        }\n",
    "\n",
    "        print(test_params)\n",
    "\n",
    "        estimator = Estimator()\n",
    "\n",
    "        clf = GridSearchCV(\n",
    "            estimator,\n",
    "            param_grid=test_params,\n",
    "            scoring=\"precision\",\n",
    "            \n",
    "            cv=TimeSeriesSplit(n_splits=2)\n",
    "        )\n",
    "\n",
    " \n",
    "        #print(X_validation.shape, y_validation.shape)\n",
    "        #print(X_validation.index[0], y_validation.index[0])\n",
    "        selected = clf.fit(X_validation, y_validation)\n",
    "\n",
    "    \n",
    "        \n",
    "        best_estimator = clf.best_estimator_\n",
    "        y_pred = best_estimator.predict(X_test)\n",
    "     \n",
    "        \n",
    "        comp_metrics = compute_metrics(y_test, y_pred)\n",
    "        #print(\"Metrics \", comp_metrics)\n",
    "\n",
    "        with open(f\"../results_2/{alg}_metrics.txt\", \"a\") as file:\n",
    "        # Write content to the file\n",
    "            file.write(f\"data-{i} {str(best_estimator.get_params())} {str(comp_metrics)}\\n\")\n",
    "        \n",
    "      \n",
    "        \n",
    "        transposed_data = zip(*[selected.cv_results_[key] for key in selected.cv_results_])\n",
    "        is_empty = (\n",
    "            not os.path.exists(f\"../results_2/{alg}-precision.csv\")\n",
    "            or os.path.getsize(f\"../results_2/{alg}-precision.csv\") == 0\n",
    "        )\n",
    "\n",
    "        with open(f\"../results_2/{alg}-precision.csv\", \"a\", newline=\"\") as f:\n",
    "            writer = csv.writer(f)\n",
    "\n",
    "            # Write headers only if the file is empty\n",
    "            if is_empty:\n",
    "                writer.writerow(selected.cv_results_.keys())\n",
    "\n",
    "            # Write data rows\n",
    "            writer.writerows(transposed_data)\n",
    "\n",
    "            \n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_estimator = clf.best_estimator_\n",
    "print(\"Best params \", selected.best_params_)\n",
    "y_pred = best_estimator.predict(X_test)\n",
    "print(selected.cv_results_[\"mean_test_score\"])   \n",
    "\n",
    "comp_metrics = compute_metrics(y_test, y_pred)\n",
    "print(\"Metrics \", comp_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Estimator(max_features=1, contamination=0.01, max_samples=100).fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(Estimator().fit(X,y).predict(X)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected.cv_results_[\"params\"][0][\"alg\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys_list = list(selected.cv_results_.keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in selected.cv_results_:\n",
    "    print(key)\n",
    "    print(type(selected.cv_results_[key]))\n",
    "    print(len(selected.cv_results_[key]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected.best_params_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_estimator = clf.best_estimator_\n",
    "y_pred = best_estimator.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = metrics.roc_curve(y, y_pred)\n",
    "roc_auc = metrics.auc(fpr, tpr)\n",
    "print(fpr, tpr)\n",
    "display = metrics.RocCurveDisplay(fpr=fpr, tpr=tpr, roc_auc=roc_auc, estimator_name='')\n",
    "display.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = compute_metrics(y_pred, y)\n",
    "plt.plot(fpr, tpr, color=\"blue\", lw=2, label=f\"AUC = {roc_auc}\\n Conf_matrix={metrics[0]}\\n Precision={metrics[1]}\\n Recall={metrics[2]}\\n F1={metrics[3]}\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_isolation = pd.read_csv('results_1/IsolationForest-precision.csv')\n",
    "\n",
    "print(\"IsolationForest\")\n",
    "for i in range(1, 10):\n",
    "    mask = df_isolation['param_train_data'].eq(f'data/train/ads-{i}.csv')\n",
    "    df = df_isolation[mask]\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    max_row = df.iloc[df['mean_test_score'].idxmax()]\n",
    "    print(f'data{i}.csv', 'Max samples=',max_row.param_max_samples, 'Contamination=',max_row.param_contamination, 'Split0 f1=',max_row.split0_test_score, \"Split1 f1=\",max_row.split1_test_score,'Mean f1=',max_row.mean_test_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_DBscan = pd.read_csv('results_1/DBscan-precision.csv')\n",
    "for i in range(1, 10):\n",
    "    mask = df_DBscan['param_train_data'].eq(f'data/train/ads-{i}.csv')\n",
    "    df = df_DBscan[mask]\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    max_row = df.iloc[df['mean_test_score'].idxmax()]\n",
    "    print(f'data{i}.csv', 'eps=',max_row.param_eps, 'Min samples=',max_row.param_min_samples, 'Treshold=', max_row.param_db_treshold, 'Split0 precision=',max_row.split0_test_score, 'Split1 precision=',max_row.split1_test_score, \"Mean precision=\",max_row.mean_test_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_kmeans = pd.read_csv('results_1/Kmeans-precision.csv')\n",
    "for i in range(1, 10):\n",
    "    mask = df_kmeans['param_train_data'].eq(f'data/train/ads-{i}.csv')\n",
    "    df = df_kmeans[mask]\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    max_row = df.iloc[df['mean_test_score'].idxmax()]\n",
    "    print(f'data{i}.csv', 'n_clusters=',max_row.param_n_clusters, 'Treshold=', max_row.param_treshold, 'Split0 precision=',max_row.split0_test_score, 'Split1 precision=',max_row.split1_test_score, \"Mean precision=\",max_row.mean_test_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_kmeans = pd.read_csv('results_1/Percentile-precision.csv')\n",
    "\n",
    "for i in range(1, 10):\n",
    "    mask = df_kmeans['param_train_data'].eq(f'data/train/ads-{i}.csv')\n",
    "    df = df_kmeans[mask]\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    max_row = df.iloc[df['mean_test_score'].idxmax()]\n",
    "    print(f'data{i}.csv', 'percentile_range = ', max_row.param_percentile_range , 'Split0 precision=',max_row.split0_test_score, 'Split1 precision=',max_row.split1_test_score, \"Mean precision=\",max_row.mean_test_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_border = pd.read_csv('results_1/BorderCheck-precision.csv')\n",
    "\n",
    "for i in range(1, 10):\n",
    "    mask = df_border['param_train_data'].eq(f'data/train/ads-{i}.csv')\n",
    "    df = df_border[mask]\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    max_row = df.iloc[df['mean_test_score'].idxmax()]\n",
    "    print(f'data{i}.csv', 'LL = ', max_row.param_LL , \"UL = \", max_row.param_UL, 'Split0 precision=',max_row.split0_test_score, 'Split1 precision=',max_row.split1_test_score, \"Mean precision=\",max_row.mean_test_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame([[1, 1.5], [3, 4], [5, 6]], columns=['int', 'float'])\n",
    "df.index = range(3, 3 + len(df))\n",
    "\n",
    "\n",
    "for idx, i in df.iterrows():\n",
    "    print(idx)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = {\"a\": 5, \"b\":1, \"c\":5}\n",
    "k = {\"a\":2}\n",
    "\n",
    "j = {\"a\":1,\n",
    "     **m}\n",
    "print(j)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm, datasets\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "iris = datasets.load_iris()\n",
    "parameters = {'kernel':('linear', 'rbf'), 'C':np.arange(1,10,0.01)}\n",
    "svc = svm.SVC()\n",
    "clf = GridSearchCV(svc, parameters, n_jobs=-1)\n",
    "clf.fit(iris.data, iris.target)\n",
    "sorted(clf.cv_results_.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils.estimator_checks import check_estimator\n",
    "from sklearn.svm import LinearSVC\n",
    "check_estimator(LinearSVC())  # passes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing as mp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_grid_search(params):\n",
    "    \n",
    "    i = params[\"i\"]\n",
    "\n",
    "\n",
    "    df_validation = pd.read_csv(f\"data/validation/ads-{i}.csv\")\n",
    "    X_validation = df_validation[[\"timestamp\", \"ftr_vector\"]]\n",
    "    y_validation = df_validation[[\"label\"]]\n",
    "\n",
    "\n",
    "    df_test = pd.read_csv(f\"data/test/ads-{i}.csv\")\n",
    "    X_test = df_validation[[\"timestamp\", \"ftr_vector\"]]\n",
    "    y_test = df_validation[[\"label\"]]\n",
    "\n",
    "\n",
    "    test_params = {\n",
    "        \n",
    "        # Kmeans\n",
    "        \"n_clusters\": [2],\n",
    "        \"treshold\": [0.3],\n",
    "        # DBscan\n",
    "        \"eps\": [params[\"eps\"]],\n",
    "        \"db_treshold\": [params[\"db_treshold\"]],\n",
    "        \"min_samples\": [params[\"min_samples\"]],\n",
    "        # IsolationForest\n",
    "        \"max_samples\": [10],\n",
    "        \"max_features\": [1],\n",
    "        \"contamination\": [0.01],\n",
    "        # GAN\n",
    "        \"N_latent\": [3],\n",
    "        \"K\": [8],\n",
    "        \"len_window\": [500],\n",
    "        # Border Check\n",
    "        \"UL\": [0.5],\n",
    "        \"LL\":  [-0.5],\n",
    "        \"alg\":[\"DBscan\"],\n",
    "        \"train_data\": [f\"data/train/ads-{i}.csv\"],\n",
    "\n",
    "    }\n",
    "\n",
    "    print(test_params)\n",
    "\n",
    "    estimator = Estimator()\n",
    "\n",
    "    clf = GridSearchCV(\n",
    "        estimator,\n",
    "        param_grid=test_params,\n",
    "        scoring=\"precision\",\n",
    "        \n",
    "        cv=TimeSeriesSplit(n_splits=2)\n",
    "    )\n",
    "\n",
    "\n",
    "    #print(X_validation.shape, y_validation.shape)\n",
    "    #print(X_validation.index[0], y_validation.index[0])\n",
    "    selected = clf.fit(X_validation, y_validation)\n",
    "\n",
    "\n",
    "    \n",
    "    best_estimator = clf.best_estimator_\n",
    "    y_pred = best_estimator.predict(X_test)\n",
    "\n",
    "\n",
    "    comp_metrics = compute_metrics(y_test, y_pred)\n",
    "    print(\"Metrics \", comp_metrics)\n",
    "    \n",
    "\n",
    "    \n",
    "    transposed_data = zip(*[selected.cv_results_[key] for key in selected.cv_results_])\n",
    "    is_empty = (\n",
    "        not os.path.exists(f\"results_1/DBscan-precision.csv\")\n",
    "        or os.path.getsize(f\"results_1/DBscan-precision.csv\") == 0\n",
    "    )\n",
    "\n",
    "    with open(f\"results_1/DBscan-precision.csv\", \"a\", newline=\"\") as f:\n",
    "        writer = csv.writer(f)\n",
    "\n",
    "        # Write headers only if the file is empty\n",
    "        if is_empty:\n",
    "            writer.writerow(selected.cv_results_.keys())\n",
    "\n",
    "        # Write data rows\n",
    "        writer.writerows(transposed_data)\n",
    "\n",
    "      \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define db_params_params_list dynamically\n",
    "dbscan_params_list = [\n",
    "    {\"eps\": eps, \"db_treshold\": db_treshold, \"min_samples\": min_samples, \"i\": i}\n",
    "    for eps in np.arange(0.1, 0.2, 0.1)\n",
    "    for db_treshold in np.arange(0.05, 0.1, 0.1)\n",
    "    for min_samples in np.arange(50, 60, 50)\n",
    "    for  i in np.arange(1,5,1)\n",
    "]\n",
    "\n",
    "batch_size = 2\n",
    "\n",
    "for i in range(0, len(dbscan_params_list), batch_size):\n",
    "    batch_params = dbscan_params_list[i:i+batch_size]\n",
    "    processes = []\n",
    "    for params in batch_params:\n",
    "        p = mp.Process(target=perform_grid_search, args=(params,))\n",
    "        processes.append(p)\n",
    "        p.start()\n",
    "\n",
    "    # Wait for all processes in the current batch to finish\n",
    "    for p in processes:\n",
    "        p.join()\n",
    "\n",
    "    time.sleep(15)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "X = np.array([[1, 2], [3, 4], [1, 2], [3, 4], [1, 2], [3, 4], [4, 5], [1, 2], [3, 4], [4, 5]])\n",
    "y = np.array([1, 2, 3, 4, 5, 6, 7, 5, 6, 7])\n",
    "tscv = TimeSeriesSplit(n_splits=2)\n",
    "print(tscv)\n",
    "for i, (train_index, test_index) in enumerate(tscv.split(X)):\n",
    "    print(f\"Fold {i}:\")\n",
    "    print(f\"  Train: index={train_index}\")\n",
    "    print(f\"  Test:  index={test_index}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.gradient(np.array([5,3, 5]), [1, 2, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "a_det2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
