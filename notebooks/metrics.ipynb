{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-05 16:50:21.360522: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2024-04-05 16:50:21.360550: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import sklearn.metrics\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "import numpy as np\n",
    "from typing import Any, Dict, List, Tuple, Union\n",
    "from sklearn import metrics\n",
    "\n",
    "from src.algorithms.kmeans import Kmeans\n",
    "from src.algorithms.dbscan import DBscan\n",
    "from src.algorithms.isolation_forest import IsolationForest\n",
    "from src.algorithms.percentile import Percentile\n",
    "\n",
    "from src.algorithms.gan import GAN\n",
    "from src.algorithms.border_check import BorderCheck\n",
    "from src.algorithms.svm import SVM\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin, TransformerMixin\n",
    "from sklearn.utils.validation import check_X_y, check_array, check_is_fitted\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "from sklearn.metrics import euclidean_distances\n",
    "from sklearn.model_selection import GridSearchCV, TimeSeriesSplit\n",
    "from sklearn.utils.estimator_checks import check_estimator\n",
    "import csv\n",
    "import os\n",
    "import multiprocessing as mp\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(y_true, y_predicted):\n",
    "    confusion_matrix = sklearn.metrics.confusion_matrix(y_true, y_predicted)\n",
    "    precision = sklearn.metrics.precision_score(y_true, y_predicted)\n",
    "    recall = sklearn.metrics.recall_score(y_true, y_predicted)\n",
    "    f1 = sklearn.metrics.f1_score(y_true, y_predicted)\n",
    "    accuracy = sklearn.metrics.accuracy_score(y_true, y_predicted)\n",
    "\n",
    "    return {\"confusion matrix \": confusion_matrix, \"precision \": precision, \"recall \": recall, \"f1 \": f1, \"accuracy \" : accuracy}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nparam_grid_Kmeans = {\\n    \"n_clusters\": np.arange(2, 4),\\n    \"treshold\": np.arange(0.1, 1, 0.1),\\n}\\n\\nparam_grid_DBscan = {\\n    \"eps\": np.arange(0.5, 1.5, 0.5),\\n    \"treshold\": np.arange(0.5, 2, 0.5),\\n    \"min_samples\": np.arange(1, 3, 1),\\n}\\n\\nalgorithms_params = [param_grid_Kmeans] \\nalgorithms = [\"Kmeans\"]\\n\\nmetrics = np.empty([2, 2, 5], dtype=object)\\n\\nfor i in range(1,2):\\n\\n    df_test = pd.read_csv(f\"data/sensor-cleaning-data/cleaned/test/reformatted/data1.csv\")\\n\\n    y_true = df_test[[\"error\"]]\\n\\n    for alg_id, alg in enumerate(algorithms_params):\\n        score = []\\n        for params in itertools.product(*alg.values()):\\n\\n            inner_dict = {k: v for (k, v) in zip(algorithms_params[alg_id].keys(), params)}\\n\\n            conf = {\\n                \"filtering\": \"None\",\\n                \"train_data\": f\"data/sensor-cleaning-data/cleaned/train/data{i}.csv\",\\n                \"input_vector_size\": 1,\\n                \"warning_stages\": [0.7, 0.9],\\n                **inner_dict,\\n                \"output\": [],\\n                \"output_conf\": [{}\\n                ],\\n            }\\n\\n            class_name = algorithms[alg_id]\\n\\n            class_ = globals()[class_name]\\n\\n            detector = class_(conf)\\n\\n            mask = []\\n            y_predicted = []\\n\\n            for idx, row in df_test.iterrows():\\n\\n                status_code = detector.message_insert(\\n                    {\\n                        \"timestamp\": df_test[\"offset\"].iloc[idx],\\n                        \"ftr_vector\": [df_test[\"val\"].iloc[idx]],\\n                    }\\n                )\\n\\n                if status_code == 2:\\n                    y_predicted.append(False)\\n                if status_code == 1:\\n                    y_predicted.append(False)\\n                elif status_code == -1:\\n                    y_predicted.append(True)\\n\\n\\n            m = compute_metrics(y_predicted, y_true)\\n            m.append(params)\\n            score.append(m)\\n            print(m)\\n            #print(f\"{algorithms[alg_id]}\", score)\\n        #print(max(score, key=lambda x: x[0]))\\n        # max_list = max(score, key=lambda x: x[3])\\n\\n        # metrics[alg_id, i-1, :] = max_list\\n\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "param_grid_Kmeans = {\n",
    "    \"n_clusters\": np.arange(2, 4),\n",
    "    \"treshold\": np.arange(0.1, 1, 0.1),\n",
    "}\n",
    "\n",
    "param_grid_DBscan = {\n",
    "    \"eps\": np.arange(0.5, 1.5, 0.5),\n",
    "    \"treshold\": np.arange(0.5, 2, 0.5),\n",
    "    \"min_samples\": np.arange(1, 3, 1),\n",
    "}\n",
    "\n",
    "algorithms_params = [param_grid_Kmeans] \n",
    "algorithms = [\"Kmeans\"]\n",
    "\n",
    "metrics = np.empty([2, 2, 5], dtype=object)\n",
    "\n",
    "for i in range(1,2):\n",
    "\n",
    "    df_test = pd.read_csv(f\"data/sensor-cleaning-data/cleaned/test/reformatted/data1.csv\")\n",
    "\n",
    "    y_true = df_test[[\"error\"]]\n",
    "\n",
    "    for alg_id, alg in enumerate(algorithms_params):\n",
    "        score = []\n",
    "        for params in itertools.product(*alg.values()):\n",
    "\n",
    "            inner_dict = {k: v for (k, v) in zip(algorithms_params[alg_id].keys(), params)}\n",
    "\n",
    "            conf = {\n",
    "                \"filtering\": \"None\",\n",
    "                \"train_data\": f\"data/sensor-cleaning-data/cleaned/train/data{i}.csv\",\n",
    "                \"input_vector_size\": 1,\n",
    "                \"warning_stages\": [0.7, 0.9],\n",
    "                **inner_dict,\n",
    "                \"output\": [],\n",
    "                \"output_conf\": [{}\n",
    "                ],\n",
    "            }\n",
    "\n",
    "            class_name = algorithms[alg_id]\n",
    "\n",
    "            class_ = globals()[class_name]\n",
    "\n",
    "            detector = class_(conf)\n",
    "\n",
    "            mask = []\n",
    "            y_predicted = []\n",
    "\n",
    "            for idx, row in df_test.iterrows():\n",
    "\n",
    "                status_code = detector.message_insert(\n",
    "                    {\n",
    "                        \"timestamp\": df_test[\"offset\"].iloc[idx],\n",
    "                        \"ftr_vector\": [df_test[\"val\"].iloc[idx]],\n",
    "                    }\n",
    "                )\n",
    "\n",
    "                if status_code == 2:\n",
    "                    y_predicted.append(False)\n",
    "                if status_code == 1:\n",
    "                    y_predicted.append(False)\n",
    "                elif status_code == -1:\n",
    "                    y_predicted.append(True)\n",
    "\n",
    "\n",
    "            m = compute_metrics(y_predicted, y_true)\n",
    "            m.append(params)\n",
    "            score.append(m)\n",
    "            print(m)\n",
    "            #print(f\"{algorithms[alg_id]}\", score)\n",
    "        #print(max(score, key=lambda x: x[0]))\n",
    "        # max_list = max(score, key=lambda x: x[3])\n",
    "\n",
    "        # metrics[alg_id, i-1, :] = max_list\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndf_test = pd.read_csv(f\"data/sensor-cleaning-data/cleaned/test/reformatted/data1.csv\")\\n# select to columns from dataframe\\nX = df_test[[\"offset\", \"val\"]]\\ny = df_test[[\"error\"]]\\n\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "df_test = pd.read_csv(f\"data/sensor-cleaning-data/cleaned/test/reformatted/data1.csv\")\n",
    "# select to columns from dataframe\n",
    "X = df_test[[\"offset\", \"val\"]]\n",
    "y = df_test[[\"error\"]]\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Estimator(BaseEstimator):\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        \n",
    "        train_data=\"data/train/ads-1.csv\",\n",
    "        alg = \"Kmeans\",\n",
    "\n",
    "        # Kmeans \n",
    "        n_clusters=1,\n",
    "        treshold=1,\n",
    "\n",
    "        #DBscan\n",
    "        eps = 0.5,\n",
    "        db_treshold=1,\n",
    "        min_samples = 2,\n",
    "\n",
    "        #IsolationForest\n",
    "        max_samples = 100,\n",
    "        max_features=1,\n",
    "        contamination = 0.05,\n",
    "\n",
    "        # GAN\n",
    "        N_latent=3,\n",
    "        K=8,\n",
    "        len_window=500,\n",
    "\n",
    "        # BorderCheck\n",
    "        UL=0.5,\n",
    "        LL=-0.5,\n",
    "\n",
    "        #Percentile\n",
    "        percentile_range = [(1, 99)],\n",
    "        buff_size = [50]\n",
    "        \n",
    "       \n",
    "    ):\n",
    "        self.train_data = train_data\n",
    "        self.alg = alg\n",
    "\n",
    "        # Kmeans\n",
    "        self.n_clusters = n_clusters\n",
    "        self.treshold = treshold\n",
    "\n",
    "        # DBscan\n",
    "        self.eps = eps\n",
    "        self.min_samples = min_samples\n",
    "        self.db_treshold = db_treshold\n",
    "\n",
    "        # IsolationForest\n",
    "        self.max_samples = max_samples \n",
    "        self.max_features = max_features\n",
    "        self.contamination = contamination\n",
    "\n",
    "        # GAN\n",
    "        self.N_latent = N_latent\n",
    "        self.K = K\n",
    "        self.len_window = len_window\n",
    "\n",
    "        # BorderCheck\n",
    "        self.UL = UL\n",
    "        self.LL = LL \n",
    "\n",
    "        # Percentile\n",
    "        self.percentile_range = percentile_range\n",
    "        self.buff_size = buff_size\n",
    "\n",
    "\n",
    "    def fit(self, X, y):\n",
    "\n",
    "        inner_dict = {\n",
    "            \"train_data\": self.train_data,\n",
    "            # Kmeans\n",
    "            \"n_clusters\": self.n_clusters,\n",
    "            \"treshold\": self.treshold,\n",
    "            # DBscan\n",
    "            \"eps\": self.eps,\n",
    "            \"min_samples\": self.min_samples,\n",
    "            \"db_treshold\": self.db_treshold,\n",
    "            # IsolationForest\n",
    "            \"max_samples\": self.max_samples,\n",
    "            \"max_features\": self.max_features,\n",
    "            \"contamination\": self.contamination,\n",
    "            # GAN\n",
    "            \"N_latent\": self.N_latent,\n",
    "            \"K\": self.K,\n",
    "            \"len_window\": self.len_window,\n",
    "            # BorderCheck\n",
    "            \"UL\": self.UL,\n",
    "            \"LL\": self.LL,\n",
    "            # Percentile\n",
    "            \"percentile_range\": self.percentile_range,\n",
    "            \"buff_size\": self.buff_size\n",
    "\n",
    "        }\n",
    "\n",
    "        conf = {\n",
    "            \"filtering\": \"None\",\n",
    "            \"input_vector_size\": 1,\n",
    "            \"warning_stages\": [0.7, 0.9],\n",
    "            \"model_name\":\"IsolationForest\",\n",
    "            **inner_dict,\n",
    "            \"output\": [],\n",
    "            \"output_conf\": [{}],\n",
    "        }\n",
    "\n",
    "      \n",
    "\n",
    "        class_ = globals()[self.alg]\n",
    "        self.detector_ = class_(conf)\n",
    "\n",
    "        self.is_fitted_ = True\n",
    "\n",
    "        # `fit` should always return `self`\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        \n",
    "        y_predicted = []\n",
    "                \n",
    "    \n",
    "        # transverse X rows\n",
    "        \n",
    "        for idx, row in X.iterrows():\n",
    "            \n",
    "          \n",
    "            message = {\n",
    "                \"timestamp\": row[\"timestamp\"],\n",
    "                \"ftr_vector\": [row[\"ftr_vector\"]],\n",
    "            }\n",
    "          \n",
    "        \n",
    "            status_code = self.detector_.message_insert(message)\n",
    "\n",
    "            if status_code == 2 or status_code ==0:\n",
    "                y_predicted.append(False)\n",
    "            if status_code == 1:\n",
    "                y_predicted.append(False)\n",
    "            elif status_code == -1:\n",
    "                y_predicted.append(True)\n",
    "\n",
    "           \n",
    "       \n",
    "      \n",
    "\n",
    "        \n",
    "        return y_predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_clusters': [2], 'treshold': [0.5], 'eps': [0.5], 'db_treshold': [0.5], 'min_samples': [100], 'max_samples': [10], 'max_features': [1], 'contamination': [0.01], 'N_latent': [3], 'K': [8], 'len_window': [500], 'UL': [0.5], 'LL': [-0.5], 'percentile_range': [(1, 99)], 'buff_size': [100], 'train_data': ['data/train/ads-1.csv']}\n",
      "{'n_clusters': [2], 'treshold': [0.5], 'eps': [0.5], 'db_treshold': [0.5], 'min_samples': [100], 'max_samples': [10], 'max_features': [1], 'contamination': [0.01], 'N_latent': [3], 'K': [8], 'len_window': [500], 'UL': [0.5], 'LL': [-0.5], 'percentile_range': [(1, 99)], 'buff_size': [100], 'train_data': ['data/train/ads-2.csv']}\n",
      "{'n_clusters': [2], 'treshold': [0.5], 'eps': [0.5], 'db_treshold': [0.5], 'min_samples': [100], 'max_samples': [10], 'max_features': [1], 'contamination': [0.01], 'N_latent': [3], 'K': [8], 'len_window': [500], 'UL': [0.5], 'LL': [-0.5], 'percentile_range': [(1, 99)], 'buff_size': [100], 'train_data': ['data/train/ads-3.csv']}\n",
      "{'n_clusters': [2], 'treshold': [0.5], 'eps': [0.5], 'db_treshold': [0.5], 'min_samples': [100], 'max_samples': [10], 'max_features': [1], 'contamination': [0.01], 'N_latent': [3], 'K': [8], 'len_window': [500], 'UL': [0.5], 'LL': [-0.5], 'percentile_range': [(1, 99)], 'buff_size': [100], 'train_data': ['data/train/ads-4.csv']}\n",
      "{'n_clusters': [2], 'treshold': [0.5], 'eps': [0.5], 'db_treshold': [0.5], 'min_samples': [100], 'max_samples': [10], 'max_features': [1], 'contamination': [0.01], 'N_latent': [3], 'K': [8], 'len_window': [500], 'UL': [0.5], 'LL': [-0.5], 'percentile_range': [(1, 99)], 'buff_size': [100], 'train_data': ['data/train/ads-5.csv']}\n",
      "{'n_clusters': [2], 'treshold': [0.5], 'eps': [0.5], 'db_treshold': [0.5], 'min_samples': [100], 'max_samples': [10], 'max_features': [1], 'contamination': [0.01], 'N_latent': [3], 'K': [8], 'len_window': [500], 'UL': [0.5], 'LL': [-0.5], 'percentile_range': [(1, 99)], 'buff_size': [100], 'train_data': ['data/train/ads-6.csv']}\n",
      "{'n_clusters': [2], 'treshold': [0.5], 'eps': [0.5], 'db_treshold': [0.5], 'min_samples': [100], 'max_samples': [10], 'max_features': [1], 'contamination': [0.01], 'N_latent': [3], 'K': [8], 'len_window': [500], 'UL': [0.5], 'LL': [-0.5], 'percentile_range': [(1, 99)], 'buff_size': [100], 'train_data': ['data/train/ads-7.csv']}\n",
      "{'n_clusters': [2], 'treshold': [0.5], 'eps': [0.5], 'db_treshold': [0.5], 'min_samples': [100], 'max_samples': [10], 'max_features': [1], 'contamination': [0.01], 'N_latent': [3], 'K': [8], 'len_window': [500], 'UL': [0.5], 'LL': [-0.5], 'percentile_range': [(1, 99)], 'buff_size': [100], 'train_data': ['data/train/ads-8.csv']}\n",
      "{'n_clusters': [2], 'treshold': [0.5], 'eps': [0.5], 'db_treshold': [0.5], 'min_samples': [100], 'max_samples': [10], 'max_features': [1], 'contamination': [0.01], 'N_latent': [3], 'K': [8], 'len_window': [500], 'UL': [0.5], 'LL': [-0.5], 'percentile_range': [(1, 99)], 'buff_size': [100], 'train_data': ['data/train/ads-9.csv']}\n"
     ]
    }
   ],
   "source": [
    "algorithms = [\"SVM\"]\n",
    "\n",
    "DBscan_params = {\n",
    "    \n",
    "    \"alg\": [\"DBscan\"],\n",
    "   \n",
    "    # DBscan\n",
    "    \"eps\": np.arange(0.1, 1, 0.1),\n",
    "    \"db_treshold\": np.arange(0.05, 1, 0.05),\n",
    "    \"min_samples\": [100, 200],\n",
    "   \n",
    "}\n",
    "\n",
    "Kmeans_params = {\n",
    "    \n",
    "    \"alg\": [\"Kmeans\"],\n",
    "    # Kmeans\n",
    "    \"n_clusters\": [2, 4, 6],\n",
    "    \"treshold\": np.arange(0.05, 1, 0.05),\n",
    "}\n",
    "\n",
    "IsolationForest_params = {\n",
    "    \"alg\": [\"IsolationForest\"],\n",
    "  \n",
    "    # IsolationForest\n",
    "    \"max_samples\": [2500],\n",
    "    \"max_features\": [1],\n",
    "    \"contamination\": [0.0005, 0.001, 0.003, 0.008],\n",
    "\n",
    "}\n",
    "\n",
    "BorderCheck_params = {\n",
    "    \"alg\": [\"BorderCheck\"],\n",
    "  \n",
    "    \"UL\": np.arange(0.3, 2.1, 0.2),\n",
    "    \"LL\": np.arange(-0.1, -2.1, -0.2),\n",
    "\n",
    "}\n",
    "\n",
    "first_values = [0.2, 0.5, 0.7, 1, 2]\n",
    "second_values = [99, 99.2, 99.5, 99.8, 99.95]  \n",
    "\n",
    "# Create a list of tuples with all combinations of values\n",
    "list_of_tuples = [(first, second) for first, second in itertools.product(first_values, second_values)]\n",
    "\n",
    "Percentile_params = {\n",
    "    \"alg\": [\"Percentile\"],\n",
    "  \n",
    "    \"percentile_range\":list_of_tuples,\n",
    "    \"buff_size\": [1000]\n",
    "\n",
    "}\n",
    "\n",
    "\n",
    "SVM_params = {\n",
    "   \n",
    "\n",
    "}\n",
    "\n",
    "\n",
    "for alg in algorithms:\n",
    "\n",
    "    for i in range(1, 10):\n",
    "\n",
    "        df_validation = pd.read_csv(f\"data/validation/ads-{i}.csv\")\n",
    "        X_validation = df_validation[[\"timestamp\", \"ftr_vector\"]]\n",
    "        y_validation = df_validation[[\"label\"]]\n",
    "\n",
    "\n",
    "        df_test = pd.read_csv(f\"data/test/ads-{i}.csv\")\n",
    "        X_test = df_test[[\"timestamp\", \"ftr_vector\"]]\n",
    "        y_test = df_test[[\"label\"]]\n",
    "\n",
    "\n",
    "        test_params = {\n",
    "            \n",
    "            # Kmeans\n",
    "            \"n_clusters\": [2],\n",
    "            \"treshold\": [0.5],\n",
    "\n",
    "            # DBscan\n",
    "            \"eps\": [0.5],\n",
    "            \"db_treshold\": [0.5],\n",
    "            \"min_samples\": [100],\n",
    "\n",
    "            # IsolationForest\n",
    "            \"max_samples\": [10],\n",
    "            \"max_features\": [1],\n",
    "            \"contamination\": [0.01],\n",
    "\n",
    "            # GAN\n",
    "            \"N_latent\": [3],\n",
    "            \"K\": [8],\n",
    "            \"len_window\": [500],\n",
    "\n",
    "            # Border Check\n",
    "            \"UL\": [0.5],\n",
    "            \"LL\":  [-0.5],\n",
    "\n",
    "            # Percentile\n",
    "            \"percentile_range\":[(1,99)],\n",
    "            \"buff_size\":[100],\n",
    "\n",
    "            **eval(f\"{alg}_params\"),\n",
    "            \"train_data\": [f\"data/train/ads-{i}.csv\"],\n",
    "     \n",
    "        }\n",
    "\n",
    "        print(test_params)\n",
    "\n",
    "        estimator = Estimator()\n",
    "\n",
    "        clf = GridSearchCV(\n",
    "            estimator,\n",
    "            param_grid=test_params,\n",
    "            scoring=\"precision\",\n",
    "            \n",
    "            cv=TimeSeriesSplit(n_splits=2)\n",
    "        )\n",
    "\n",
    " \n",
    "        #print(X_validation.shape, y_validation.shape)\n",
    "        #print(X_validation.index[0], y_validation.index[0])\n",
    "        selected = clf.fit(X_validation, y_validation)\n",
    "\n",
    "    \n",
    "        \n",
    "        best_estimator = clf.best_estimator_\n",
    "        y_pred = best_estimator.predict(X_test)\n",
    "     \n",
    "\n",
    "        comp_metrics = compute_metrics(y_test, y_pred)\n",
    "        #print(\"Metrics \", comp_metrics)\n",
    "\n",
    "        with open(f\"results_1/{alg}_metrics.txt\", \"a\") as file:\n",
    "        # Write content to the file\n",
    "            file.write(f\"data-{i} {str(best_estimator.get_params())} {str(comp_metrics)}\\n\")\n",
    "        \n",
    "      \n",
    "        \n",
    "        transposed_data = zip(*[selected.cv_results_[key] for key in selected.cv_results_])\n",
    "        is_empty = (\n",
    "            not os.path.exists(f\"results_1/{alg}-precision.csv\")\n",
    "            or os.path.getsize(f\"results_1/{alg}-precision.csv\") == 0\n",
    "        )\n",
    "\n",
    "        with open(f\"results_1/{alg}-precision.csv\", \"a\", newline=\"\") as f:\n",
    "            writer = csv.writer(f)\n",
    "\n",
    "            # Write headers only if the file is empty\n",
    "            if is_empty:\n",
    "                writer.writerow(selected.cv_results_.keys())\n",
    "\n",
    "            # Write data rows\n",
    "            writer.writerows(transposed_data)\n",
    "\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_estimator = clf.best_estimator_\n",
    "print(\"Best params \", selected.best_params_)\n",
    "y_pred = best_estimator.predict(X_test)\n",
    "print(selected.cv_results_[\"mean_test_score\"])   \n",
    "\n",
    "comp_metrics = compute_metrics(y_test, y_pred)\n",
    "print(\"Metrics \", comp_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Estimator(max_features=1, contamination=0.01, max_samples=100).fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(Estimator().fit(X,y).predict(X)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected.cv_results_[\"params\"][0][\"alg\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys_list = list(selected.cv_results_.keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in selected.cv_results_:\n",
    "    print(key)\n",
    "    print(type(selected.cv_results_[key]))\n",
    "    print(len(selected.cv_results_[key]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected.best_params_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_estimator = clf.best_estimator_\n",
    "y_pred = best_estimator.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = metrics.roc_curve(y, y_pred)\n",
    "roc_auc = metrics.auc(fpr, tpr)\n",
    "print(fpr, tpr)\n",
    "display = metrics.RocCurveDisplay(fpr=fpr, tpr=tpr, roc_auc=roc_auc, estimator_name='')\n",
    "display.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = compute_metrics(y_pred, y)\n",
    "plt.plot(fpr, tpr, color=\"blue\", lw=2, label=f\"AUC = {roc_auc}\\n Conf_matrix={metrics[0]}\\n Precision={metrics[1]}\\n Recall={metrics[2]}\\n F1={metrics[3]}\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IsolationForest\n",
      "data1.csv Max samples= 2500 Contamination= 0.001 Split0 f1= 1.0 Split1 f1= 1.0 Mean f1= 1.0\n",
      "data2.csv Max samples= 2500 Contamination= 0.001 Split0 f1= 1.0 Split1 f1= 1.0 Mean f1= 1.0\n",
      "data3.csv Max samples= 2500 Contamination= 0.003 Split0 f1= 1.0 Split1 f1= 1.0 Mean f1= 1.0\n",
      "data4.csv Max samples= 2500 Contamination= 0.0005 Split0 f1= 1.0 Split1 f1= 1.0 Mean f1= 1.0\n",
      "data5.csv Max samples= 2500 Contamination= 0.0005 Split0 f1= 1.0 Split1 f1= 1.0 Mean f1= 1.0\n",
      "data6.csv Max samples= 2500 Contamination= 0.0005 Split0 f1= 1.0 Split1 f1= 1.0 Mean f1= 1.0\n",
      "data7.csv Max samples= 2500 Contamination= 0.0005 Split0 f1= 1.0 Split1 f1= 1.0 Mean f1= 1.0\n",
      "data8.csv Max samples= 2500 Contamination= 0.0005 Split0 f1= 1.0 Split1 f1= 1.0 Mean f1= 1.0\n",
      "data9.csv Max samples= 2500 Contamination= 0.001 Split0 f1= 0.3333333333333333 Split1 f1= 1.0 Mean f1= 0.6666666666666666\n"
     ]
    }
   ],
   "source": [
    "df_isolation = pd.read_csv('results_1/IsolationForest-precision.csv')\n",
    "\n",
    "print(\"IsolationForest\")\n",
    "for i in range(1, 10):\n",
    "    mask = df_isolation['param_train_data'].eq(f'data/train/ads-{i}.csv')\n",
    "    df = df_isolation[mask]\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    max_row = df.iloc[df['mean_test_score'].idxmax()]\n",
    "    print(f'data{i}.csv', 'Max samples=',max_row.param_max_samples, 'Contamination=',max_row.param_contamination, 'Split0 f1=',max_row.split0_test_score, \"Split1 f1=\",max_row.split1_test_score,'Mean f1=',max_row.mean_test_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data1.csv eps= 0.4 Min samples= 100 Treshold= 0.05 Split0 precision= 1.0 Split1 precision= 1.0 Mean precision= 1.0\n",
      "data2.csv eps= 0.2 Min samples= 100 Treshold= 0.05 Split0 precision= 1.0 Split1 precision= 1.0 Mean precision= 1.0\n",
      "data3.csv eps= 0.3 Min samples= 100 Treshold= 0.05 Split0 precision= 1.0 Split1 precision= 1.0 Mean precision= 1.0\n",
      "data4.csv eps= 0.7000000000000001 Min samples= 100 Treshold= 0.05 Split0 precision= 1.0 Split1 precision= 1.0 Mean precision= 1.0\n",
      "data5.csv eps= 0.7000000000000001 Min samples= 100 Treshold= 0.05 Split0 precision= 1.0 Split1 precision= 1.0 Mean precision= 1.0\n",
      "data6.csv eps= 0.9 Min samples= 100 Treshold= 0.05 Split0 precision= 1.0 Split1 precision= 1.0 Mean precision= 1.0\n",
      "data7.csv eps= 0.9 Min samples= 100 Treshold= 0.05 Split0 precision= 1.0 Split1 precision= 1.0 Mean precision= 1.0\n",
      "data8.csv eps= 0.9 Min samples= 100 Treshold= 0.5 Split0 precision= 1.0 Split1 precision= 0.6666666666666666 Mean precision= 0.8333333333333333\n",
      "data9.csv eps= 0.8 Min samples= 100 Treshold= 0.9000000000000001 Split0 precision= 1.0 Split1 precision= 1.0 Mean precision= 1.0\n"
     ]
    }
   ],
   "source": [
    "df_DBscan = pd.read_csv('results_1/DBscan-precision.csv')\n",
    "for i in range(1, 10):\n",
    "    mask = df_DBscan['param_train_data'].eq(f'data/train/ads-{i}.csv')\n",
    "    df = df_DBscan[mask]\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    max_row = df.iloc[df['mean_test_score'].idxmax()]\n",
    "    print(f'data{i}.csv', 'eps=',max_row.param_eps, 'Min samples=',max_row.param_min_samples, 'Treshold=', max_row.param_db_treshold, 'Split0 precision=',max_row.split0_test_score, 'Split1 precision=',max_row.split1_test_score, \"Mean precision=\",max_row.mean_test_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data1.csv n_clusters= 2 Treshold= 0.5 Split0 precision= 1.0 Split1 precision= 1.0 Mean precision= 1.0\n",
      "data2.csv n_clusters= 2 Treshold= 0.35 Split0 precision= 1.0 Split1 precision= 1.0 Mean precision= 1.0\n",
      "data3.csv n_clusters= 2 Treshold= 0.6000000000000001 Split0 precision= 1.0 Split1 precision= 1.0 Mean precision= 1.0\n",
      "data4.csv n_clusters= 2 Treshold= 0.95 Split0 precision= 0.3333333333333333 Split1 precision= 1.0 Mean precision= 0.6666666666666666\n",
      "data5.csv n_clusters= 6 Treshold= 0.95 Split0 precision= 1.0 Split1 precision= 0.3333333333333333 Mean precision= 0.6666666666666666\n",
      "data6.csv n_clusters= 6 Treshold= 0.95 Split0 precision= 0.3333333333333333 Split1 precision= 0.6 Mean precision= 0.4666666666666667\n",
      "data7.csv n_clusters= 6 Treshold= 0.9000000000000001 Split0 precision= 0.3333333333333333 Split1 precision= 0.6 Mean precision= 0.4666666666666667\n",
      "data8.csv n_clusters= 6 Treshold= 0.95 Split0 precision= 0.3333333333333333 Split1 precision= 0.6666666666666666 Mean precision= 0.5\n",
      "data9.csv n_clusters= 2 Treshold= 0.95 Split0 precision= 0.1666666666666666 Split1 precision= 0.3333333333333333 Mean precision= 0.25\n"
     ]
    }
   ],
   "source": [
    "df_kmeans = pd.read_csv('results_1/Kmeans-precision.csv')\n",
    "for i in range(1, 10):\n",
    "    mask = df_kmeans['param_train_data'].eq(f'data/train/ads-{i}.csv')\n",
    "    df = df_kmeans[mask]\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    max_row = df.iloc[df['mean_test_score'].idxmax()]\n",
    "    print(f'data{i}.csv', 'n_clusters=',max_row.param_n_clusters, 'Treshold=', max_row.param_treshold, 'Split0 precision=',max_row.split0_test_score, 'Split1 precision=',max_row.split1_test_score, \"Mean precision=\",max_row.mean_test_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data1.csv percentile_range =  (0.2, 99.95) Split0 precision= 0.3478260869565217 Split1 precision= 0.1612903225806451 Mean precision= 0.2545582047685834\n",
      "data2.csv percentile_range =  (0.2, 99.95) Split0 precision= 0.3333333333333333 Split1 precision= 0.1351351351351351 Mean precision= 0.2342342342342342\n",
      "data3.csv percentile_range =  (0.5, 99.95) Split0 precision= 0.3333333333333333 Split1 precision= 0.1875 Mean precision= 0.2604166666666666\n",
      "data4.csv percentile_range =  (0.5, 99.95) Split0 precision= 0.1764705882352941 Split1 precision= 0.3333333333333333 Mean precision= 0.2549019607843137\n",
      "data5.csv percentile_range =  (0.2, 99.95) Split0 precision= 0.2 Split1 precision= 0.2051282051282051 Mean precision= 0.2025641025641025\n",
      "data6.csv percentile_range =  (0.2, 99.95) Split0 precision= 0.24 Split1 precision= 0.3333333333333333 Mean precision= 0.2866666666666666\n",
      "data7.csv percentile_range =  (0.2, 99.95) Split0 precision= 0.2352941176470588 Split1 precision= 0.2727272727272727 Mean precision= 0.2540106951871658\n",
      "data8.csv percentile_range =  (0.2, 99.5) Split0 precision= 0.1470588235294117 Split1 precision= 0.1666666666666666 Mean precision= 0.1568627450980392\n",
      "data9.csv percentile_range =  (0.5, 99.95) Split0 precision= 0.1363636363636363 Split1 precision= 0.0869565217391304 Mean precision= 0.1116600790513833\n"
     ]
    }
   ],
   "source": [
    "df_kmeans = pd.read_csv('results_1/Percentile-precision.csv')\n",
    "\n",
    "for i in range(1, 10):\n",
    "    mask = df_kmeans['param_train_data'].eq(f'data/train/ads-{i}.csv')\n",
    "    df = df_kmeans[mask]\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    max_row = df.iloc[df['mean_test_score'].idxmax()]\n",
    "    print(f'data{i}.csv', 'percentile_range = ', max_row.param_percentile_range , 'Split0 precision=',max_row.split0_test_score, 'Split1 precision=',max_row.split1_test_score, \"Mean precision=\",max_row.mean_test_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data1.csv LL =  -0.5000000000000001 UL =  1.9 Split0 precision= 0.0472972972972973 Split1 precision= 0.0514285714285714 Mean precision= 0.0493629343629343\n",
      "data2.csv LL =  -0.5000000000000001 UL =  1.9 Split0 precision= 0.0516129032258064 Split1 precision= 0.0333333333333333 Mean precision= 0.0424731182795698\n",
      "data3.csv LL =  -0.7000000000000001 UL =  1.9 Split0 precision= 0.0434782608695652 Split1 precision= 0.0518134715025906 Mean precision= 0.0476458661860779\n",
      "data4.csv LL =  -1.1000000000000003 UL =  1.9 Split0 precision= 0.0476190476190476 Split1 precision= 0.057471264367816 Mean precision= 0.0525451559934318\n",
      "data5.csv LL =  -1.3000000000000005 UL =  1.9 Split0 precision= 0.0532544378698224 Split1 precision= 0.0507614213197969 Mean precision= 0.0520079295948097\n",
      "data6.csv LL =  -1.7000000000000004 UL =  1.9 Split0 precision= 0.057471264367816 Split1 precision= 0.0646766169154228 Mean precision= 0.0610739406416194\n",
      "data7.csv LL =  -1.5000000000000004 UL =  1.9 Split0 precision= 0.0465116279069767 Split1 precision= 0.0299145299145299 Mean precision= 0.0382130789107533\n",
      "data8.csv LL =  -1.5000000000000004 UL =  1.9 Split0 precision= 0.0352112676056338 Split1 precision= 0.0387323943661971 Mean precision= 0.0369718309859154\n",
      "data9.csv LL =  -1.9000000000000004 UL =  1.9 Split0 precision= 0.016260162601626 Split1 precision= 0.0229885057471264 Mean precision= 0.0196243341743762\n"
     ]
    }
   ],
   "source": [
    "df_border = pd.read_csv('results_1/BorderCheck-precision.csv')\n",
    "\n",
    "for i in range(1, 10):\n",
    "    mask = df_border['param_train_data'].eq(f'data/train/ads-{i}.csv')\n",
    "    df = df_border[mask]\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    max_row = df.iloc[df['mean_test_score'].idxmax()]\n",
    "    print(f'data{i}.csv', 'LL = ', max_row.param_LL , \"UL = \", max_row.param_UL, 'Split0 precision=',max_row.split0_test_score, 'Split1 precision=',max_row.split1_test_score, \"Mean precision=\",max_row.mean_test_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame([[1, 1.5], [3, 4], [5, 6]], columns=['int', 'float'])\n",
    "df.index = range(3, 3 + len(df))\n",
    "\n",
    "\n",
    "for idx, i in df.iterrows():\n",
    "    print(idx)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = {\"a\": 5, \"b\":1, \"c\":5}\n",
    "k = {\"a\":2}\n",
    "\n",
    "j = {\"a\":1,\n",
    "     **m}\n",
    "print(j)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm, datasets\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "iris = datasets.load_iris()\n",
    "parameters = {'kernel':('linear', 'rbf'), 'C':np.arange(1,10,0.01)}\n",
    "svc = svm.SVC()\n",
    "clf = GridSearchCV(svc, parameters, n_jobs=-1)\n",
    "clf.fit(iris.data, iris.target)\n",
    "sorted(clf.cv_results_.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils.estimator_checks import check_estimator\n",
    "from sklearn.svm import LinearSVC\n",
    "check_estimator(LinearSVC())  # passes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing as mp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_grid_search(params):\n",
    "    \n",
    "    i = params[\"i\"]\n",
    "\n",
    "\n",
    "    df_validation = pd.read_csv(f\"data/validation/ads-{i}.csv\")\n",
    "    X_validation = df_validation[[\"timestamp\", \"ftr_vector\"]]\n",
    "    y_validation = df_validation[[\"label\"]]\n",
    "\n",
    "\n",
    "    df_test = pd.read_csv(f\"data/test/ads-{i}.csv\")\n",
    "    X_test = df_validation[[\"timestamp\", \"ftr_vector\"]]\n",
    "    y_test = df_validation[[\"label\"]]\n",
    "\n",
    "\n",
    "    test_params = {\n",
    "        \n",
    "        # Kmeans\n",
    "        \"n_clusters\": [2],\n",
    "        \"treshold\": [0.3],\n",
    "        # DBscan\n",
    "        \"eps\": [params[\"eps\"]],\n",
    "        \"db_treshold\": [params[\"db_treshold\"]],\n",
    "        \"min_samples\": [params[\"min_samples\"]],\n",
    "        # IsolationForest\n",
    "        \"max_samples\": [10],\n",
    "        \"max_features\": [1],\n",
    "        \"contamination\": [0.01],\n",
    "        # GAN\n",
    "        \"N_latent\": [3],\n",
    "        \"K\": [8],\n",
    "        \"len_window\": [500],\n",
    "        # Border Check\n",
    "        \"UL\": [0.5],\n",
    "        \"LL\":  [-0.5],\n",
    "        \"alg\":[\"DBscan\"],\n",
    "        \"train_data\": [f\"data/train/ads-{i}.csv\"],\n",
    "\n",
    "    }\n",
    "\n",
    "    print(test_params)\n",
    "\n",
    "    estimator = Estimator()\n",
    "\n",
    "    clf = GridSearchCV(\n",
    "        estimator,\n",
    "        param_grid=test_params,\n",
    "        scoring=\"precision\",\n",
    "        \n",
    "        cv=TimeSeriesSplit(n_splits=2)\n",
    "    )\n",
    "\n",
    "\n",
    "    #print(X_validation.shape, y_validation.shape)\n",
    "    #print(X_validation.index[0], y_validation.index[0])\n",
    "    selected = clf.fit(X_validation, y_validation)\n",
    "\n",
    "\n",
    "    \n",
    "    best_estimator = clf.best_estimator_\n",
    "    y_pred = best_estimator.predict(X_test)\n",
    "\n",
    "\n",
    "    comp_metrics = compute_metrics(y_test, y_pred)\n",
    "    print(\"Metrics \", comp_metrics)\n",
    "    \n",
    "\n",
    "    \n",
    "    transposed_data = zip(*[selected.cv_results_[key] for key in selected.cv_results_])\n",
    "    is_empty = (\n",
    "        not os.path.exists(f\"results_1/DBscan-precision.csv\")\n",
    "        or os.path.getsize(f\"results_1/DBscan-precision.csv\") == 0\n",
    "    )\n",
    "\n",
    "    with open(f\"results_1/DBscan-precision.csv\", \"a\", newline=\"\") as f:\n",
    "        writer = csv.writer(f)\n",
    "\n",
    "        # Write headers only if the file is empty\n",
    "        if is_empty:\n",
    "            writer.writerow(selected.cv_results_.keys())\n",
    "\n",
    "        # Write data rows\n",
    "        writer.writerows(transposed_data)\n",
    "\n",
    "      \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define db_params_params_list dynamically\n",
    "dbscan_params_list = [\n",
    "    {\"eps\": eps, \"db_treshold\": db_treshold, \"min_samples\": min_samples, \"i\": i}\n",
    "    for eps in np.arange(0.1, 0.2, 0.1)\n",
    "    for db_treshold in np.arange(0.05, 0.1, 0.1)\n",
    "    for min_samples in np.arange(50, 60, 50)\n",
    "    for  i in np.arange(1,5,1)\n",
    "]\n",
    "\n",
    "batch_size = 2\n",
    "\n",
    "for i in range(0, len(dbscan_params_list), batch_size):\n",
    "    batch_params = dbscan_params_list[i:i+batch_size]\n",
    "    processes = []\n",
    "    for params in batch_params:\n",
    "        p = mp.Process(target=perform_grid_search, args=(params,))\n",
    "        processes.append(p)\n",
    "        p.start()\n",
    "\n",
    "    # Wait for all processes in the current batch to finish\n",
    "    for p in processes:\n",
    "        p.join()\n",
    "\n",
    "    time.sleep(15)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "a_det2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
