{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sklearn.metrics\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "import numpy as np\n",
    "from typing import Any, Dict, List, Tuple, Union\n",
    "from sklearn import metrics\n",
    "\n",
    "from src.algorithms.kmeans import Kmeans\n",
    "from src.algorithms.dbscan import DBscan\n",
    "from src.algorithms.isolation_forest import IsolationForest\n",
    "from src.algorithms.gan import GAN\n",
    "from src.algorithms.border_check import BorderCheck\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin, TransformerMixin\n",
    "from sklearn.utils.validation import check_X_y, check_array, check_is_fitted\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "from sklearn.metrics import euclidean_distances\n",
    "from sklearn.model_selection import GridSearchCV, TimeSeriesSplit\n",
    "from sklearn.utils.estimator_checks import check_estimator\n",
    "import csv\n",
    "import os\n",
    "import multiprocessing as mp\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(y_true, y_predicted):\n",
    "    confusion_matrix = sklearn.metrics.confusion_matrix(y_true, y_predicted)\n",
    "    precision = sklearn.metrics.precision_score(y_true, y_predicted)\n",
    "    recall = sklearn.metrics.recall_score(y_true, y_predicted)\n",
    "    f1 = sklearn.metrics.f1_score(y_true, y_predicted)\n",
    "    accuracy = sklearn.metrics.accuracy_score(y_true, y_predicted)\n",
    "\n",
    "    return {\"confusion matrix \": confusion_matrix, \"precision \": precision, \"recall \": recall, \"f1 \": f1, \"accuracy \" : accuracy}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "param_grid_Kmeans = {\n",
    "    \"n_clusters\": np.arange(2, 4),\n",
    "    \"treshold\": np.arange(0.1, 1, 0.1),\n",
    "}\n",
    "\n",
    "param_grid_DBscan = {\n",
    "    \"eps\": np.arange(0.5, 1.5, 0.5),\n",
    "    \"treshold\": np.arange(0.5, 2, 0.5),\n",
    "    \"min_samples\": np.arange(1, 3, 1),\n",
    "}\n",
    "\n",
    "algorithms_params = [param_grid_Kmeans] \n",
    "algorithms = [\"Kmeans\"]\n",
    "\n",
    "metrics = np.empty([2, 2, 5], dtype=object)\n",
    "\n",
    "for i in range(1,2):\n",
    "\n",
    "    df_test = pd.read_csv(f\"data/sensor-cleaning-data/cleaned/test/reformatted/data1.csv\")\n",
    "\n",
    "    y_true = df_test[[\"error\"]]\n",
    "\n",
    "    for alg_id, alg in enumerate(algorithms_params):\n",
    "        score = []\n",
    "        for params in itertools.product(*alg.values()):\n",
    "\n",
    "            inner_dict = {k: v for (k, v) in zip(algorithms_params[alg_id].keys(), params)}\n",
    "\n",
    "            conf = {\n",
    "                \"filtering\": \"None\",\n",
    "                \"train_data\": f\"data/sensor-cleaning-data/cleaned/train/data{i}.csv\",\n",
    "                \"input_vector_size\": 1,\n",
    "                \"warning_stages\": [0.7, 0.9],\n",
    "                **inner_dict,\n",
    "                \"output\": [],\n",
    "                \"output_conf\": [{}\n",
    "                ],\n",
    "            }\n",
    "\n",
    "            class_name = algorithms[alg_id]\n",
    "\n",
    "            class_ = globals()[class_name]\n",
    "\n",
    "            detector = class_(conf)\n",
    "\n",
    "            mask = []\n",
    "            y_predicted = []\n",
    "\n",
    "            for idx, row in df_test.iterrows():\n",
    "\n",
    "                status_code = detector.message_insert(\n",
    "                    {\n",
    "                        \"timestamp\": df_test[\"offset\"].iloc[idx],\n",
    "                        \"ftr_vector\": [df_test[\"val\"].iloc[idx]],\n",
    "                    }\n",
    "                )\n",
    "\n",
    "                if status_code == 2:\n",
    "                    y_predicted.append(False)\n",
    "                if status_code == 1:\n",
    "                    y_predicted.append(False)\n",
    "                elif status_code == -1:\n",
    "                    y_predicted.append(True)\n",
    "\n",
    "\n",
    "            m = compute_metrics(y_predicted, y_true)\n",
    "            m.append(params)\n",
    "            score.append(m)\n",
    "            print(m)\n",
    "            #print(f\"{algorithms[alg_id]}\", score)\n",
    "        #print(max(score, key=lambda x: x[0]))\n",
    "        # max_list = max(score, key=lambda x: x[3])\n",
    "\n",
    "        # metrics[alg_id, i-1, :] = max_list\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "df_test = pd.read_csv(f\"data/sensor-cleaning-data/cleaned/test/reformatted/data1.csv\")\n",
    "# select to columns from dataframe\n",
    "X = df_test[[\"offset\", \"val\"]]\n",
    "y = df_test[[\"error\"]]\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Estimator(BaseEstimator):\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        \n",
    "        train_data=\"data/train/ads-1.csv\",\n",
    "        alg = \"Kmeans\",\n",
    "\n",
    "        # Kmeans \n",
    "        n_clusters=1,\n",
    "        treshold=1,\n",
    "\n",
    "        #DBscan\n",
    "        eps = 0.5,\n",
    "        db_treshold=1,\n",
    "        min_samples = 2,\n",
    "\n",
    "        #IsolationForest\n",
    "        max_samples = 100,\n",
    "        max_features=1,\n",
    "        contamination = 0.05,\n",
    "\n",
    "        # GAN\n",
    "        N_latent=3,\n",
    "        K=8,\n",
    "        len_window=500,\n",
    "\n",
    "        # BorderCheck\n",
    "        UL=0.5,\n",
    "        LL=-0.5\n",
    "\n",
    "        \n",
    "       \n",
    "    ):\n",
    "        self.train_data = train_data\n",
    "        self.alg = alg\n",
    "\n",
    "        # Kmeans\n",
    "        self.n_clusters = n_clusters\n",
    "        self.treshold = treshold\n",
    "\n",
    "        # DBscan\n",
    "        self.eps = eps\n",
    "        self.min_samples = min_samples\n",
    "        self.db_treshold = db_treshold\n",
    "\n",
    "        # IsolationForest\n",
    "        self.max_samples = max_samples \n",
    "        self.max_features = max_features\n",
    "        self.contamination = contamination\n",
    "\n",
    "        # GAN\n",
    "        self.N_latent = N_latent\n",
    "        self.K = K\n",
    "        self.len_window = len_window\n",
    "\n",
    "        # BorderCheck\n",
    "        self.UL = UL\n",
    "        self.LL = LL \n",
    "\n",
    "\n",
    "    def fit(self, X, y):\n",
    "\n",
    "        inner_dict = {\n",
    "            \"train_data\": self.train_data,\n",
    "            # Kmeans\n",
    "            \"n_clusters\": self.n_clusters,\n",
    "            \"treshold\": self.treshold,\n",
    "            # DBscan\n",
    "            \"eps\": self.eps,\n",
    "            \"min_samples\": self.min_samples,\n",
    "            \"db_treshold\": self.db_treshold,\n",
    "            # IsolationForest\n",
    "            \"max_samples\": self.max_samples,\n",
    "            \"max_features\": self.max_features,\n",
    "            \"contamination\": self.contamination,\n",
    "            # GAN\n",
    "            \"N_latent\": self.N_latent,\n",
    "            \"K\": self.K,\n",
    "            \"len_window\": self.len_window,\n",
    "            # BorderCheck\n",
    "            \"UL\": self.UL,\n",
    "            \"LL\": self.LL,\n",
    "\n",
    "        }\n",
    "\n",
    "        conf = {\n",
    "            \"filtering\": \"None\",\n",
    "            \"input_vector_size\": 1,\n",
    "            \"warning_stages\": [0.7, 0.9],\n",
    "            \"model_name\":\"IsolationForest\",\n",
    "            **inner_dict,\n",
    "            \"output\": [],\n",
    "            \"output_conf\": [{}],\n",
    "        }\n",
    "\n",
    "      \n",
    "\n",
    "        class_ = globals()[self.alg]\n",
    "        self.detector_ = class_(conf)\n",
    "\n",
    "        self.is_fitted_ = True\n",
    "\n",
    "        # `fit` should always return `self`\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        \n",
    "        y_predicted = []\n",
    "                \n",
    "    \n",
    "        # transverse X rows\n",
    "        \n",
    "        for idx, row in X.iterrows():\n",
    "            \n",
    "          \n",
    "            message = {\n",
    "                \"timestamp\": row[\"timestamp\"],\n",
    "                \"ftr_vector\": [row[\"ftr_vector\"]],\n",
    "            }\n",
    "          \n",
    "        \n",
    "            status_code = self.detector_.message_insert(message)\n",
    "\n",
    "            if status_code == 2 or status_code ==0:\n",
    "                y_predicted.append(False)\n",
    "            if status_code == 1:\n",
    "                y_predicted.append(False)\n",
    "            elif status_code == -1:\n",
    "                y_predicted.append(True)\n",
    "\n",
    "           \n",
    "       \n",
    "      \n",
    "\n",
    "        \n",
    "        return y_predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "algorithms = [\"Kmeans\"]\n",
    "\n",
    "DBscan_params = {\n",
    "    \n",
    "    \"alg\": [\"DBscan\"],\n",
    "   \n",
    "    # DBscan\n",
    "    \"eps\": np.arange(0.1, 1, 0.1),\n",
    "    \"db_treshold\": np.arange(0.05, 1, 0.05),\n",
    "    \"min_samples\": np.arange(15, 50, 15),\n",
    "   \n",
    "}\n",
    "\n",
    "Kmeans_params = {\n",
    "    \n",
    "    \"alg\": [\"Kmeans\"],\n",
    "    # Kmeans\n",
    "    \"n_clusters\": [2, 4],\n",
    "    \"treshold\": [0.1, 0.15],\n",
    "}\n",
    "\n",
    "IsolationForest_params = {\n",
    "    \"alg\": [\"IsolationForest\"],\n",
    "  \n",
    "    # IsolationForest\n",
    "    \"max_samples\": np.arange(2500, 10001, 2500),\n",
    "    \"max_features\": [1],\n",
    "    \"contamination\": np.arange(0.001, 0.01, 0.001),\n",
    "\n",
    "}\n",
    "\n",
    "BorderCheck_params = {\n",
    "    \"alg\": [\"BorderCheck\"],\n",
    "  \n",
    "    \"UL\": np.arange(0.1, 1.1, 0.1),\n",
    "    \"LL\": np.arange(-0.1, -1.1, -0.1),\n",
    "\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for alg in algorithms:\n",
    "\n",
    "    for i in range(1, 2):\n",
    "\n",
    "        df_validation = pd.read_csv(f\"data/validation/ads-{i}.csv\")\n",
    "        X_validation = df_validation[[\"timestamp\", \"ftr_vector\"]]\n",
    "        y_validation = df_validation[[\"label\"]]\n",
    "\n",
    "\n",
    "        df_test = pd.read_csv(f\"data/test/ads-{i}.csv\")\n",
    "        X_test = df_validation[[\"timestamp\", \"ftr_vector\"]]\n",
    "        y_test = df_validation[[\"label\"]]\n",
    "\n",
    "\n",
    "        test_params = {\n",
    "            \n",
    "            # Kmeans\n",
    "            \"n_clusters\": [2],\n",
    "            \"treshold\": [0.5],\n",
    "            # DBscan\n",
    "            \"eps\": [0.5],\n",
    "            \"db_treshold\": [0.5],\n",
    "            \"min_samples\": [100],\n",
    "            # IsolationForest\n",
    "            \"max_samples\": [10],\n",
    "            \"max_features\": [1],\n",
    "            \"contamination\": [0.01],\n",
    "            # GAN\n",
    "            \"N_latent\": [3],\n",
    "            \"K\": [8],\n",
    "            \"len_window\": [500],\n",
    "            # Border Check\n",
    "            \"UL\": [0.5],\n",
    "            \"LL\":  [-0.5],\n",
    "            **eval(f\"{alg}_params\"),\n",
    "            \"train_data\": [f\"data/train/ads-{i}.csv\"],\n",
    "     \n",
    "        }\n",
    "\n",
    "        print(test_params)\n",
    "\n",
    "        estimator = Estimator()\n",
    "\n",
    "        clf = GridSearchCV(\n",
    "            estimator,\n",
    "            param_grid=test_params,\n",
    "            scoring=\"precision\",\n",
    "            \n",
    "            cv=TimeSeriesSplit(n_splits=2)\n",
    "        )\n",
    "\n",
    " \n",
    "        #print(X_validation.shape, y_validation.shape)\n",
    "        #print(X_validation.index[0], y_validation.index[0])\n",
    "        selected = clf.fit(X_validation, y_validation)\n",
    "\n",
    "    \n",
    "        \n",
    "        #best_estimator = clf.best_estimator_\n",
    "        #y_pred = best_estimator.predict(X_test)\n",
    "     \n",
    "\n",
    "        #comp_metrics = compute_metrics(y_test, y_pred)\n",
    "        #print(\"Metrics \", comp_metrics)\n",
    "        \n",
    "    '''  \n",
    "        \n",
    "        transposed_data = zip(*[selected.cv_results_[key] for key in selected.cv_results_])\n",
    "        is_empty = (\n",
    "            not os.path.exists(f\"results_1/Kmeans-precision.csv\")\n",
    "            or os.path.getsize(f\"results_1/Kmeans-precision.csv\") == 0\n",
    "        )\n",
    "\n",
    "        with open(f\"results_1/Kmeans-precision.csv\", \"a\", newline=\"\") as f:\n",
    "            writer = csv.writer(f)\n",
    "\n",
    "            # Write headers only if the file is empty\n",
    "            if is_empty:\n",
    "                writer.writerow(selected.cv_results_.keys())\n",
    "\n",
    "            # Write data rows\n",
    "            writer.writerows(transposed_data)\n",
    "\n",
    "    '''  \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_estimator = clf.best_estimator_\n",
    "print(\"Best params \", selected.best_params_)\n",
    "y_pred = best_estimator.predict(X_test)\n",
    "print(selected.cv_results_[\"mean_test_score\"])   \n",
    "\n",
    "comp_metrics = compute_metrics(y_test, y_pred)\n",
    "print(\"Metrics \", comp_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Estimator(max_features=1, contamination=0.01, max_samples=100).fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(Estimator().fit(X,y).predict(X)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected.cv_results_[\"params\"][0][\"alg\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys_list = list(selected.cv_results_.keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in selected.cv_results_:\n",
    "    print(key)\n",
    "    print(type(selected.cv_results_[key]))\n",
    "    print(len(selected.cv_results_[key]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected.best_params_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_estimator = clf.best_estimator_\n",
    "y_pred = best_estimator.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = metrics.roc_curve(y, y_pred)\n",
    "roc_auc = metrics.auc(fpr, tpr)\n",
    "print(fpr, tpr)\n",
    "display = metrics.RocCurveDisplay(fpr=fpr, tpr=tpr, roc_auc=roc_auc, estimator_name='')\n",
    "display.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = compute_metrics(y_pred, y)\n",
    "plt.plot(fpr, tpr, color=\"blue\", lw=2, label=f\"AUC = {roc_auc}\\n Conf_matrix={metrics[0]}\\n Precision={metrics[1]}\\n Recall={metrics[2]}\\n F1={metrics[3]}\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_isolation = pd.read_csv('results_1/IsolationForest.csv')\n",
    "\n",
    "print(\"IsolationForest\")\n",
    "for i in range(1, 9):\n",
    "    mask = df_isolation['param_train_data'].str.split('/').str[-1].eq(f'data{i}.csv')\n",
    "    df = df_isolation[mask]\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    max_row = df.iloc[df['mean_test_score'].idxmax()]\n",
    "    print(f'data{i}.csv', 'Max samples=',max_row.param_max_samples, 'Contamination=',max_row.param_contamination, 'Split0 f1=',max_row.split0_test_score, \"Split1 f1=\",max_row.split1_test_score,'Mean f1=',max_row.mean_test_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_DBscan = pd.read_csv('results_1/DBscan.csv')\n",
    "\n",
    "for i in range(1, 10):\n",
    "    mask = df_DBscan['param_train_data'].str.split('/').str[-1].eq(f'data{i}.csv')\n",
    "    df = df_DBscan[mask]\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    max_row = df.iloc[df['split1_test_score'].idxmax()]\n",
    "    print(f'data{i}.csv', 'eps=',max_row.param_eps, 'Min samples=',max_row.param_min_samples, 'Treshold=', max_row.param_db_treshold, 'Split0 f1=',max_row.split0_test_score, 'Split1 f1=',max_row.split1_test_score, \"Mean f1=\",max_row.mean_test_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_kmeans = pd.read_csv('results_1/Kmeans.csv')\n",
    "\n",
    "for i in range(1, 5):\n",
    "    mask = df_kmeans['param_train_data'].eq(f'data/train/ads-{i}.csv')\n",
    "    df = df_kmeans[mask]\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    max_row = df.iloc[df['mean_test_score'].idxmax()]\n",
    "    print(f'data{i}.csv', 'n_clusters=',max_row.param_n_clusters, 'Treshold=', max_row.param_treshold, 'Split0 f1=',max_row.split0_test_score, 'Split1 f1=',max_row.split1_test_score, \"Mean f1=\",max_row.mean_test_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame([[1, 1.5], [3, 4], [5, 6]], columns=['int', 'float'])\n",
    "df.index = range(3, 3 + len(df))\n",
    "\n",
    "\n",
    "for idx, i in df.iterrows():\n",
    "    print(idx)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = {\"a\": 5, \"b\":1, \"c\":5}\n",
    "k = {\"a\":2}\n",
    "\n",
    "j = {\"a\":1,\n",
    "     **m}\n",
    "print(j)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm, datasets\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "iris = datasets.load_iris()\n",
    "parameters = {'kernel':('linear', 'rbf'), 'C':np.arange(1,10,0.01)}\n",
    "svc = svm.SVC()\n",
    "clf = GridSearchCV(svc, parameters, n_jobs=-1)\n",
    "clf.fit(iris.data, iris.target)\n",
    "sorted(clf.cv_results_.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils.estimator_checks import check_estimator\n",
    "from sklearn.svm import LinearSVC\n",
    "check_estimator(LinearSVC())  # passes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing as mp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_grid_search(params):\n",
    "    \n",
    "    i = params[\"i\"]\n",
    "\n",
    "\n",
    "    df_validation = pd.read_csv(f\"data/validation/ads-{i}.csv\")\n",
    "    X_validation = df_validation[[\"timestamp\", \"ftr_vector\"]]\n",
    "    y_validation = df_validation[[\"label\"]]\n",
    "\n",
    "\n",
    "    df_test = pd.read_csv(f\"data/test/ads-{i}.csv\")\n",
    "    X_test = df_validation[[\"timestamp\", \"ftr_vector\"]]\n",
    "    y_test = df_validation[[\"label\"]]\n",
    "\n",
    "\n",
    "    test_params = {\n",
    "        \n",
    "        # Kmeans\n",
    "        \"n_clusters\": [2],\n",
    "        \"treshold\": [0.3],\n",
    "        # DBscan\n",
    "        \"eps\": [params[\"eps\"]],\n",
    "        \"db_treshold\": [params[\"db_treshold\"]],\n",
    "        \"min_samples\": [params[\"min_samples\"]],\n",
    "        # IsolationForest\n",
    "        \"max_samples\": [10],\n",
    "        \"max_features\": [1],\n",
    "        \"contamination\": [0.01],\n",
    "        # GAN\n",
    "        \"N_latent\": [3],\n",
    "        \"K\": [8],\n",
    "        \"len_window\": [500],\n",
    "        # Border Check\n",
    "        \"UL\": [0.5],\n",
    "        \"LL\":  [-0.5],\n",
    "        \"alg\":[\"DBscan\"],\n",
    "        \"train_data\": [f\"data/train/ads-{i}.csv\"],\n",
    "\n",
    "    }\n",
    "\n",
    "    print(test_params)\n",
    "\n",
    "    estimator = Estimator()\n",
    "\n",
    "    clf = GridSearchCV(\n",
    "        estimator,\n",
    "        param_grid=test_params,\n",
    "        scoring=\"precision\",\n",
    "        \n",
    "        cv=TimeSeriesSplit(n_splits=2)\n",
    "    )\n",
    "\n",
    "\n",
    "    #print(X_validation.shape, y_validation.shape)\n",
    "    #print(X_validation.index[0], y_validation.index[0])\n",
    "    selected = clf.fit(X_validation, y_validation)\n",
    "\n",
    "\n",
    "    \n",
    "    best_estimator = clf.best_estimator_\n",
    "    y_pred = best_estimator.predict(X_test)\n",
    "\n",
    "\n",
    "    comp_metrics = compute_metrics(y_test, y_pred)\n",
    "    print(\"Metrics \", comp_metrics)\n",
    "    \n",
    "\n",
    "    \n",
    "    transposed_data = zip(*[selected.cv_results_[key] for key in selected.cv_results_])\n",
    "    is_empty = (\n",
    "        not os.path.exists(f\"results_1/DBscan-precision.csv\")\n",
    "        or os.path.getsize(f\"results_1/DBscan-precision.csv\") == 0\n",
    "    )\n",
    "\n",
    "    with open(f\"results_1/DBscan-precision.csv\", \"a\", newline=\"\") as f:\n",
    "        writer = csv.writer(f)\n",
    "\n",
    "        # Write headers only if the file is empty\n",
    "        if is_empty:\n",
    "            writer.writerow(selected.cv_results_.keys())\n",
    "\n",
    "        # Write data rows\n",
    "        writer.writerows(transposed_data)\n",
    "\n",
    "      \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define db_params_params_list dynamically\n",
    "dbscan_params_list = [\n",
    "    {\"eps\": eps, \"db_treshold\": db_treshold, \"min_samples\": min_samples, \"i\": i}\n",
    "    for eps in np.arange(0.1, 0.2, 0.1)\n",
    "    for db_treshold in np.arange(0.05, 0.1, 0.1)\n",
    "    for min_samples in np.arange(50, 60, 50)\n",
    "    for  i in np.arange(1,5,1)\n",
    "]\n",
    "\n",
    "batch_size = 2\n",
    "\n",
    "for i in range(0, len(dbscan_params_list), batch_size):\n",
    "    batch_params = dbscan_params_list[i:i+batch_size]\n",
    "    processes = []\n",
    "    for params in batch_params:\n",
    "        p = mp.Process(target=perform_grid_search, args=(params,))\n",
    "        processes.append(p)\n",
    "        p.start()\n",
    "\n",
    "    # Wait for all processes in the current batch to finish\n",
    "    for p in processes:\n",
    "        p.join()\n",
    "\n",
    "    time.sleep(15)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "a_det2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
